{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_inference_ckpt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEyRD9HmhfViQmQ5fTlMrv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edurso/tfod-wkspc/blob/master/test_inference_ckpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfbe5sOf0O6h",
        "outputId": "720c38d0-24d2-4091-a001-a42bc8d319c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /tf/data; to attempt to forcibly remount, call drive.mount(\"/tf/data\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /tf/models /tf/workspace\n",
        "!mkdir -p /tf/data\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/tf/data')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# install deps \n",
        "python --version\n",
        "pip install -U --pre tensorflow==\"2.*\"\n",
        "pip install tf_slim pycocotools\n",
        "\n",
        "# clone repos\n",
        "mkdir -p /tf/models/ /tf/workspace/\n",
        "git clone --depth 1 https://github.com/tensorflow/models /tf/models\n",
        "git clone --depth 1 https://github.com/edurso/tfod-wkspc /tf/workspace\n",
        "\n",
        "# compile protobufs\n",
        "cd /tf/models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# install object detector package\n",
        "cp /tf/models/research/object_detection/packages/tf2/setup.py . \n",
        "pip install ."
      ],
      "metadata": {
        "id": "pQl1OEYt0hQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import cv2 as cv\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "o_0R__Lb04Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def get_keypoint_tuples(eval_config):\n",
        "  \"\"\"Return a tuple list of keypoint edges from the eval config.\n",
        "  \n",
        "  Args:\n",
        "    eval_config: an eval config containing the keypoint edges\n",
        "  \n",
        "  Returns:\n",
        "    a list of edge tuples, each in the format (start, end)\n",
        "  \"\"\"\n",
        "  tuple_list = []\n",
        "  kp_list = eval_config.keypoint_edge\n",
        "  for edge in kp_list:\n",
        "    tuple_list.append((edge.start, edge.end))\n",
        "  return tuple_list"
      ],
      "metadata": {
        "id": "qgBaHlg00_G5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/tf/data/MyDrive/tensorflow/power-port-targeting/'\n",
        "SAVED_MODEL = PATH + 'exported-models/trained_model/'\n",
        "PIPELINE = SAVED_MODEL + 'pipeline.config'\n",
        "LABEL_MAP = PATH + 'annotations/label_map.pbtxt'\n",
        "MODEL_DIR = SAVED_MODEL + 'checkpoint/' # to ckpt or saved model?\n",
        "IMAGES = PATH + 'images/test/'\n",
        "IMG = 'frame-321.jpg'"
      ],
      "metadata": {
        "id": "1vGOnhgE2ba6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = PIPELINE #os.path.join('models/research/object_detection/configs/tf2/', model_name + '.config')\n",
        "model_dir = MODEL_DIR #'models/research/object_detection/test_data/checkpoint/'\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "metadata": {
        "id": "AMFuYlnx1I6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map_path = LABEL_MAP #configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "metadata": {
        "id": "hdLwitZB1qkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = IMAGES #'models/research/object_detection/test_images/'\n",
        "image_path = os.path.join(image_dir, IMG) # os.path.join(image_dir, 'image2.jpg')\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# Things to try:\n",
        "# Flip horizontally\n",
        "# image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "# Convert image to grayscale\n",
        "# image_np = np.tile(\n",
        "#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "# Use keypoints if available in detections\n",
        "keypoints, keypoint_scores = None, None\n",
        "if 'detection_keypoints' in detections:\n",
        "  keypoints = detections['detection_keypoints'][0].numpy()\n",
        "  keypoint_scores = detections['detection_keypoint_scores'][0].numpy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.30,\n",
        "      agnostic_mode=False,\n",
        "      keypoints=keypoints,\n",
        "      keypoint_scores=keypoint_scores,\n",
        "      keypoint_edges=get_keypoint_tuples(configs['eval_config']))\n",
        "\n",
        "plt.figure(figsize=(12,16))\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OSNX-mX73c8q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}