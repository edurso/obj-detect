{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow-object-detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPT5tUdiRzBR4dN+atVc3gB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edurso/tfod-wkspc/blob/master/tensorflow-object-detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup Workspace"
      ],
      "metadata": {
        "id": "L4l4ZvBDhiF0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYI-h-F0dCm2"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# install deps \n",
        "python --version\n",
        "pip install -U --pre tensorflow==\"2.*\"\n",
        "pip install tf_slim pycocotools\n",
        "\n",
        "# clear previous runs\n",
        "rm -rf /tf/models/ /tf/workspace/\n",
        "mkdir /tf\n",
        "\n",
        "# clone repos\n",
        "git clone --depth 1 https://github.com/tensorflow/models /tf/models\n",
        "git clone --depth 1 https://github.com/edurso/tfod-wkspc /tf/workspace\n",
        "\n",
        "# compile protobufs\n",
        "cd /content/models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# install object detector package\n",
        "cp object_detection/packages/tf2/setup.py . \n",
        "pip install .\n",
        "\n",
        "# test installation\n",
        "cd /content/models/research/object_detection/builders/\n",
        "python model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/tf/data')\n",
        "DATA='/tf/data/MyDrive/tensorflow/power-port-targeting/'\n",
        "MODEL='centernet_mobilenetv2_fpn_od'"
      ],
      "metadata": {
        "id": "7L84Quj5fh0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, go to the [model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) and copy a model to `pre-trained-models/`. \n",
        "\n",
        "Split the dataset and copy images to `images/test/` and `images/train/`.\n",
        "\n",
        "Add `label_map.pbtxt` to `annotations/`.\n",
        "\n",
        "Make a new directory in `models/` named similarly (or the same) to the model you downloaded from the zoo. Copy the `pipeline.config` file from the model you downloaded to this directory.\n",
        "\n",
        "Verify the colab runtime is configured for a GPU.\n",
        "\n",
        "Now update the `pipeline.config` in `models/` to refelect your dataset."
      ],
      "metadata": {
        "id": "huq3tJmC7oQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/tf/data/MyDrive/tensorflow/power-port-targeting/'\n",
        "\n",
        "!export SCRIPTS=\"/tf/workspace/scripts\"\n",
        "\n",
        "# Generate TFRecord for Training Data\n",
        "!python $SCRIPTS/preprocessing/generate-tfrecord.py \\\n",
        "    -x images/train \\\n",
        "    -l annotations/label_map.pbtxt \\\n",
        "    -o annotations/train.record\n",
        "\n",
        "# Generate TFRecord for Validation Data\n",
        "!python $SCRIPTS/preprocessing/generate-tfrecord.py \\\n",
        "    -x images/test \\\n",
        "    -l annotations/label_map.pbtxt \\\n",
        "    -o annotations/test.record"
      ],
      "metadata": {
        "id": "qiRKbm4kfj6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/tf/data/MyDrive/tensorflow/power-port-targeting/'\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=models/centernet_mobilenetv2_fpn_od"
      ],
      "metadata": {
        "id": "gLTld7ws_e5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/tf/data/MyDrive/tensorflow/power-port-targeting/'\n",
        "!python /tf/models/research/object_detection/model_main_tf2.py \\\n",
        "    --model_dir=models/centernet_mobilenetv2_fpn_od \\\n",
        "    --pipeline_config_path=models/centernet_mobilenetv2_fpn_od/pipeline.config"
      ],
      "metadata": {
        "id": "V9nHinNnAz1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/tf/data/MyDrive/tensorflow/power-port-targeting/'\n",
        "!python exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path ./models/centernet_mobilenetv2_fpn_od/pipeline.config \\\n",
        "    --trained_checkpoint_dir ./models/centernet_mobilenetv2_fpn_od/ \\\n",
        "    --output_directory ./exported-models/trained_model"
      ],
      "metadata": {
        "id": "_-N7gYshBGr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL=\"/tf/data/MyDrive/tensorflow/power-port-targeting/exported-models/trained_model/saved_model\"\n",
        "print('Loading model...', end='')\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "print('Done!')\n",
        "\n",
        "category_index=label_map_util.create_category_index_from_labelmap(\"/tf/data/MyDrive/tensorflow/power-port-targeting/annotations/label_map.pbtxt\", use_display_name=True)\n",
        "\n",
        "img=['/tf/data/MyDrive/tensorflow/power-port-targeting/images/test/frame-321.jpg']\n",
        "print(img)\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "for image_path in img:\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "    image_np=load_image_into_numpy_array(image_path)\n",
        "    input_tensor=tf.convert_to_tensor(image_np)\n",
        "    input_tensor=input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    detections=detect_fn(input_tensor)num_detections=int(detections.pop('num_detections'))\n",
        "    detections={key:value[0,:num_detections].numpy() for key,value in detections.items()}\n",
        "    detections['num_detections']=num_detections\n",
        "    detections['detection_classes']=detections['detection_classes'].astype(np.int64)\n",
        "    image_np_with_detections=image_np.copy()\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=100,     \n",
        "          min_score_thresh=.5,      \n",
        "          agnostic_mode=False)\n",
        "    %matplotlib inline\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "e9FNHny-BgHD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}